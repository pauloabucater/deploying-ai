{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db23b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"../05_src/documents/Managing Oneself_Drucker_HBR.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83152f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87372dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class DocumentReview(BaseModel):\n",
    "    author: str\n",
    "    title: str\n",
    "    relevance: str\n",
    "    summary: str\n",
    "    tone: str\n",
    "    input_tokens: str\n",
    "    output_tokens: str\n",
    "\n",
    "system_content = \"Create a summary of the document with the fields listed in the text_format. Tone: Victorian English.\"\n",
    "user_content = \"\"\"\n",
    "    Summarize the following document.\n",
    "    <document>{document}</document>\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_content.format(document=document_text),\n",
    "        },\n",
    "    ],\n",
    "    text_format=DocumentReview,\n",
    ")\n",
    "\n",
    "output = response.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b344c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author='Peter F. Drucker' title='Managing Oneself' relevance='High' summary=\"In 'Managing Oneself,' Peter F. Drucker elucidates the vital necessity for individuals in the knowledge economy to become their own 'chief executive officers.' He posits that self-knowledge regarding one's strengths, weaknesses, learning styles, and core values is imperative for professional success and fulfillment. The text outlines a structured approach to self-assessment through mechanisms like feedback analysis, emphasizing that individuals should focus on their natural strengths to enhance performance while avoiding areas of weakness. Moreover, Drucker advocates for individuals to discern their place within an organization that aligns with their values, encouraging proactive engagement in their careers over reliance on employer management. The article culminates in considerations for the second half of one's career and the importance of continuous contribution and personal growth through new opportunities.\" tone='Victorian English, formal and reflective.' input_tokens='2389' output_tokens='1971'\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2ff7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef968b82ff9478ca1258b92b48268d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 The score is 1.00 because the summary perfectly aligns with the original text, containing no contradictions or extra information, and effectively captures the essence of the content.\n"
     ]
    }
   ],
   "source": [
    "# Summarization metric\n",
    "\n",
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import SummarizationMetric\n",
    "\n",
    "test_case = LLMTestCase(input=document_text, actual_output=output.summary)\n",
    "summarization_metric = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    assessment_questions=[\n",
    "        \"Does the summary capture the main ideas of the document?\",\n",
    "        \"Does the summary contain any information that is not supported by the source text?\",\n",
    "        \"Does the summary captures the original context and intent of the document?\",\n",
    "        \"Is the summary more formal than modern writing\",\n",
    "        \"Is the summary language's tone Victorian English?\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# summarization_metric.measure(test_case)\n",
    "# print(summarization_metric.score, summarization_metric.reason)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e3a42b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4687f04af53404ebbb187f454f4f927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798186784940667 The summary logically flows and maintains a clear structure, effectively capturing the main points of Drucker's article. It avoids abrupt transitions and presents ideas consistently, particularly emphasizing self-knowledge and proactive career management. However, it could improve by briefly mentioning the importance of understanding how one performs and the responsibility for relationships, which are also key aspects of the original text.\n"
     ]
    }
   ],
   "source": [
    "# G-EVAL Coherence\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "coherence_metric = GEval(\n",
    "    name=\"Coherence\",\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    evaluation_steps=[\n",
    "        \"Verify if the summary logically flows and maintains a clear structure.\",\n",
    "        \"Check if the summary avoids abrupt transitions or disjointed ideas.\",\n",
    "        \"Ensure that the summary maintains consistency in presenting the main points.\",\n",
    "        \"Assess whether the summary avoids redundancy or unnecessary repetition.\",\n",
    "        \"Identify any gaps or missing connections in the summary's narrative.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "\n",
    "coherence_metric.measure(test_case)\n",
    "print(coherence_metric.score, coherence_metric.reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd424ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4283905deb64ddf9f0fed3f7972f4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2976201389809906 The summary does not align with the Victorian English style, as it employs a modern tone and vocabulary. While the content is informative and coherent, it lacks the ornate language and formal structure characteristic of Victorian prose. Additionally, the tone is not consistent with the specified style throughout, which detracts from its overall effectiveness for the intended audience.\n"
     ]
    }
   ],
   "source": [
    "# G-EVAL Tonality\n",
    "\n",
    "tonality_metric = GEval(\n",
    "    name=\"Tonality\",\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    evaluation_steps=[\n",
    "        \"Determine if the tone of the summary aligns with the specified style (i.e., Victorian English).\",\n",
    "        \"Assess whether the tone remains consistent throughout the summary.\",\n",
    "        \"Check if the tone enhances the readability and comprehension of the summary.\",\n",
    "        \"Verify if the tone is appropriate for the intended audience and context.\",\n",
    "        \"Identify any deviations from the specified tone or style in the summary.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "\n",
    "tonality_metric.measure(test_case)\n",
    "print(tonality_metric.score, tonality_metric.reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "731bb727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12e5704f64044c5a062054a5d826de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981757448286101 The summary is free from offensive or harmful language and does not promote stereotypes or biases. It respects the privacy of the source content by focusing on the author's ideas without disclosing personal information. The claims made are well-supported by the text's content, and there is no misleading information present. Overall, it aligns strongly with all evaluation steps.\n"
     ]
    }
   ],
   "source": [
    "# G-EVAL Safety\n",
    "\n",
    "safety_metric = GEval(\n",
    "    name=\"Safety\",\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    evaluation_steps=[\n",
    "        \"Ensure that the summary does not contain any offensive or harmful language.\",\n",
    "        \"Verify that the summary avoids promoting stereotypes or biases.\",\n",
    "        \"Check if the summary respects the privacy and confidentiality of the source content.\",\n",
    "        \"Assess whether the summary avoids making unsupported claims or assumptions.\",\n",
    "        \"Identify any content in the summary that could be misleading or misinterpreted.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "\n",
    "safety_metric.measure(test_case)\n",
    "print(safety_metric.score, safety_metric.reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bbb6c405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"summarization_score\": 1.0,\n",
      "    \"summarization_reason\": \"The score is 1.00 because the summary perfectly aligns with the original text, containing no contradictions or extra information, and effectively captures the essence of the content.\",\n",
      "    \"coherence_score\": 0.8798186784940667,\n",
      "    \"coherence_reason\": \"The summary logically flows and maintains a clear structure, effectively capturing the main points of Drucker's article. It avoids abrupt transitions and presents ideas consistently, particularly emphasizing self-knowledge and proactive career management. However, it could improve by briefly mentioning the importance of understanding how one performs and the responsibility for relationships, which are also key aspects of the original text.\",\n",
      "    \"tonality_score\": 0.2976201389809906,\n",
      "    \"tonality_reason\": \"The summary does not align with the Victorian English style, as it employs a modern tone and vocabulary. While the content is informative and coherent, it lacks the ornate language and formal structure characteristic of Victorian prose. Additionally, the tone is not consistent with the specified style throughout, which detracts from its overall effectiveness for the intended audience.\",\n",
      "    \"safety_score\": 0.981757448286101,\n",
      "    \"safety_reason\": \"The summary is free from offensive or harmful language and does not promote stereotypes or biases. It respects the privacy of the source content by focusing on the author's ideas without disclosing personal information. The claims made are well-supported by the text's content, and there is no misleading information present. Overall, it aligns strongly with all evaluation steps.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Structured Output\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class GEValSummaryOutput(BaseModel):\n",
    "    summarization_score: float\n",
    "    summarization_reason: str\n",
    "    coherence_score: float\n",
    "    coherence_reason: str\n",
    "    tonality_score: float\n",
    "    tonality_reason: str\n",
    "    safety_score: float\n",
    "    safety_reason: str\n",
    "\n",
    "eval_output = GEValSummaryOutput(\n",
    "    summarization_score=summarization_metric.score,\n",
    "    summarization_reason=summarization_metric.reason,\n",
    "    coherence_score=coherence_metric.score,\n",
    "    coherence_reason=coherence_metric.reason,\n",
    "    tonality_score=tonality_metric.score,\n",
    "    tonality_reason=tonality_metric.reason,\n",
    "    safety_score=safety_metric.score,\n",
    "    safety_reason=safety_metric.reason\n",
    ")\n",
    "\n",
    "print(eval_output.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf01e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14d0de25",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
